{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "997759e3-e618-49cf-89e0-586feddc88b5",
   "metadata": {},
   "source": [
    "### Classifier notebook:\n",
    " - Development of multioutput classification model that uses expected profit as metric. \n",
    " - This notebook will be cleaned up and separated into multiple notebooks so that it will be easier to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef141ef9-6546-4251-8b48-41d0239d8e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries, CLEAN THIS \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from imblearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "sns.set_theme(style='darkgrid')\n",
    "# read in the json files\n",
    "portfolio = pd.read_json('../data/raw/portfolio.json', orient='records', lines=True)\n",
    "profile = pd.read_json('../data/raw/profile.json', orient='records', lines=True)\n",
    "transcript = pd.read_json('../data/raw/transcript.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34a384ea-b92a-436f-b802-b21b41eddd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get offer ids from 'value' column, convert to float, and store in new column\n",
    "offer_ids = dict()\n",
    "indx = list(transcript[transcript['event']!='transaction'].index)\n",
    "\n",
    "for ind in indx: \n",
    "    offer_id = list(transcript.iloc[ind]['value'].values())[0]\n",
    "    offer_ids.update({ind:offer_id})\n",
    "    \n",
    "# Make dataframe from dictionary of index, offer_id strings     \n",
    "offer_id_df = pd.DataFrame.from_dict(offer_ids, orient='index', columns=['offer_ids'])\n",
    "\n",
    "# Concat transcript_mod and offer_id_df dataframes\n",
    "transcript_mod = pd.concat([transcript, offer_id_df], axis=1, ignore_index=False)\n",
    "\n",
    "# rename column 'id' as offer_ids to remain consistent with transcript df\n",
    "portfolio = portfolio.rename(columns={'id':'offer_ids'})\n",
    "\n",
    "# merge transcript and portfolio dataframes\n",
    "transcript_portfolio = transcript_mod.merge(portfolio[['offer_ids', 'offer_type']], on='offer_ids', how='left')\n",
    "\n",
    "offers = ['bogo', 'discount']\n",
    "# filter transcript_portfolio to get transcripts corresponding to BOGO offers \n",
    "offer = transcript_portfolio[transcript_portfolio['offer_type'].isin(offers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "372818d1-02e3-4484-81a5-fb3593b34b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SamaraSadeek/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:4913: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "offer.drop(['value','time', 'offer_ids'], axis=1, inplace=True)\n",
    "\n",
    "offer_per_person = offer.groupby(['person','offer_type'])['event'].value_counts().unstack()\n",
    "\n",
    "offer_per_person['offer completed'].fillna(0, inplace=True)\n",
    "\n",
    "offer_per_person['completed_per_view'] = offer_per_person['offer completed']/ offer_per_person['offer viewed']\n",
    "\n",
    "offer_per_person['completed_per_view'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f17872-0a6a-4081-a9b9-8157e3958280",
   "metadata": {},
   "source": [
    "### Computing responsiveness label for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "832b74e9-a1c3-4f19-9b81-6f40b553a361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setting_response(cpv):\n",
    "    if cpv <= 0.5: \n",
    "        return 0 \n",
    "    else: \n",
    "        return 1\n",
    "    \n",
    "offer_per_person['responds'] = offer_per_person['completed_per_view'].apply(lambda x:setting_response(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1307eb0d-47b4-467d-b0a8-355be5e1fe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_df = offer_per_person.unstack()\n",
    "offer_df = offer_df['responds']\n",
    "offer_df.dropna(inplace=True)\n",
    "offer_df = offer_df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ae531d-9129-4227-bd44-22a065988b9f",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2de052c5-b3a6-45bb-8ef5-6f57d58f317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column 'id' to 'person' to remain consistent with transcript\n",
    "profile = profile.rename(columns={'id':'person'})\n",
    "# Remove people was ages > 99\n",
    "profile = profile[profile['age'] <= 99]\n",
    "\n",
    "# Remove people with income > 1000000\n",
    "profile = profile[profile['income'] < 1000000.0]\n",
    "\n",
    "# Binarise age based on criteria old=1, young=0\n",
    "def age_group(age):\n",
    "    if age < 25:\n",
    "        return '< 25 years'\n",
    "    \n",
    "    if age < 35:\n",
    "        return '25 - 35 years'\n",
    "    \n",
    "    if age < 45:\n",
    "        return '36 - 45 years'\n",
    "    \n",
    "    if age < 66: \n",
    "        return '46 - 66 years'\n",
    "    \n",
    "    else: \n",
    "        return '67+ years'\n",
    "\n",
    "profile['age_group'] = profile['age'].apply(lambda x:age_group(x))\n",
    "\n",
    "# Binarise income based on criteria rich=1, poor=0\n",
    "def income_group(income):\n",
    "    if income < 50001: \n",
    "        return 'low income'\n",
    "    if income < 70001:\n",
    "        return 'med - low income'\n",
    "    if income < 90001:\n",
    "        return 'high - med income'\n",
    "    else:\n",
    "        return 'high income'\n",
    "\n",
    "profile['income_group'] = profile['income'].apply(lambda x:income_group(x))\n",
    "\n",
    "# select columns needed for training model\n",
    "profile_subset = profile[['person','income_group','age_group', 'gender']]\n",
    "\n",
    "# reset index to allow ease concatanation with transformed ohe data\n",
    "profile_subset = profile_subset.reset_index()\n",
    "\n",
    "profile_subset.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a35fcd34-8829-4c80-b86e-8fa82c0fdb7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile['income'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e39e24f-b0f1-48ed-b154-d2555f846056",
   "metadata": {},
   "source": [
    "### Preparing dataset to be used to train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cd21b16-7811-4e19-a2a9-667623d6aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "offer_per_person_demo = offer_df.merge(profile_subset, left_on='person',right_on='person', how='left').set_index('person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2dc4cb8-2a8f-4d41-8c10-c5864fa96079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intantiate OHE\n",
    "categorical_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    \n",
    "# List categorical variables in to be OHE\n",
    "categorical_columns = ['income_group','age_group','gender']\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "        [\n",
    "            ('cat', categorical_encoder, categorical_columns),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7771dfa-99d4-4667-b8a5-6e4ae35d99ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = offer_per_person_demo.drop(['bogo', 'discount'], axis=1)\n",
    "y = offer_per_person_demo[['bogo', 'discount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24251d8d-280c-49fa-bfa2-9610168858f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "\n",
    "\n",
    "#rus = RandomUnderSampler()\n",
    "clf = MultiOutputClassifier(RandomForestClassifier())\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        ('preprocess', preprocessing),\n",
    "        #('undersample', rus),\n",
    "        ('classifier', clf),\n",
    "    ]\n",
    "    \n",
    ")\n",
    "\n",
    "# BELOW ARE STEPS FOR HYPERTUNING CLASSIFIER\n",
    "#parameters = {'classifier__estimator__n_estimators': [120, 140, 160], 'classifier__estimator__criterion':('gini', 'entropy')}\n",
    "\n",
    "#cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "\n",
    "\n",
    "#cv.fit(X_train, y_train)\n",
    "#y_pred = cv.predict(X_test)\n",
    "#accuracy = accuracy_score(y_test, y_pred)\n",
    "#report = classification_report(y_test, y_pred, target_names=['bogo', 'discount'])\n",
    "\n",
    "#print(accuracy)\n",
    "#print(report)\n",
    "#print (multilabel_confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e49d65-a327-41c6-8b17-3d74b5cf1093",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Calculating total expected profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85d051ec-382c-42cf-8c9e-3382b78dbbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining benefits associated with true positive, true negatives\n",
    "b_tp = 10\n",
    "b_tn = 0\n",
    "\n",
    "# Defining costs (or negative benefits) associated with false postives, false negatives\n",
    "b_fp = -1\n",
    "b_fn = -10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d106196-fe1b-4b70-b31f-f0cef337f0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating probabilities needed to compute expected profit \n",
    "\n",
    "p_bogo = y_test['bogo'].value_counts().sort_index(ascending=True)[1]\n",
    "n_bogo = y_test['bogo'].value_counts().sort_index(ascending=True)[0]\n",
    "\n",
    "p_disc = y_test['discount'].value_counts().sort_index(ascending=True)[1]\n",
    "n_disc = y_test['discount'].value_counts().sort_index(ascending=True)[0]\n",
    "\n",
    "prob_p_bogo = p_bogo/(p_bogo + n_bogo)\n",
    "prob_n_bogo = n_bogo/(p_bogo + n_bogo) \n",
    "\n",
    "prob_p_disc = p_disc/(p_disc + n_disc)\n",
    "prob_n_disc = n_disc/(p_disc + n_disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d7f7c55-4967-4ee3-9cb9-d6cd8589a38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting values from confusion matrix \n",
    "\n",
    "tn_bogo, fp_bogo, fn_bogo, tp_bogo = multilabel_confusion_matrix(y_test, y_pred)[0].ravel()\n",
    "tn_disc, fp_disc, fn_disc, tp_disc = multilabel_confusion_matrix(y_test, y_pred)[1].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df30733a-cffe-4fdf-b482-66ebaa87ec69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected profit\n",
    "E_prof_bogo = (tp_bogo * prob_p_bogo * b_tp) + (fn_bogo * prob_p_bogo * b_fn)+ (tn_bogo * prob_n_bogo * b_tn) + (fp_bogo * prob_n_bogo * b_fp)\n",
    "E_prof_disc = (tp_disc * prob_p_disc * b_tp) + (fn_disc * prob_p_disc * b_fn) + (tn_disc * prob_n_disc * b_tn) + (fp_disc * prob_n_disc * b_fp)\n",
    "\n",
    "E_prof = E_prof_bogo + E_prof_disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f79518d7-0ae5-4059-adca-8fc96cc8a956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5971.416218293621"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_prof"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43509265-560a-4a1d-ad5b-8a425fcd43aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ee5613c-3721-46b8-bc37-e6acf2146bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_prof(y_test, y_pred):\n",
    "    '''\n",
    "    This function returns the expected profit which is used as a the evaluation \n",
    "    metric of the classifier.\n",
    "    '''\n",
    "    # Defining benefits associated with true positive, true negatives\n",
    "    b_tp = 10\n",
    "    b_tn = 0\n",
    "\n",
    "    # Defining costs (or negative benefits) associated with false postives, false negatives\n",
    "    b_fp = -1\n",
    "    b_fn = -10 \n",
    "\n",
    "    # Calculating probabilities needed to compute expected profit \n",
    "\n",
    "    p_bogo = y_test['bogo'].value_counts().sort_index(ascending=True)[1]\n",
    "    n_bogo = y_test['bogo'].value_counts().sort_index(ascending=True)[0]\n",
    "\n",
    "    p_disc = y_test['discount'].value_counts().sort_index(ascending=True)[1]\n",
    "    n_disc = y_test['discount'].value_counts().sort_index(ascending=True)[0]\n",
    "\n",
    "    prob_p_bogo = p_bogo/(p_bogo + n_bogo)\n",
    "    prob_n_bogo = n_bogo/(p_bogo + n_bogo) \n",
    "\n",
    "    prob_p_disc = p_disc/(p_disc + n_disc)\n",
    "    prob_n_disc = n_disc/(p_disc + n_disc)\n",
    "\n",
    "    # Extracting values from confusion matrix \n",
    "\n",
    "    tn_bogo, fp_bogo, fn_bogo, tp_bogo = multilabel_confusion_matrix(y_test, y_pred)[0].ravel()\n",
    "    tn_disc, fp_disc, fn_disc, tp_disc = multilabel_confusion_matrix(y_test, y_pred)[1].ravel()\n",
    "\n",
    "    # Expected profit\n",
    "    E_prof_bogo = (tp_bogo * prob_p_bogo * b_tp) + (fn_bogo * prob_p_bogo * b_fn)+ (tn_bogo * prob_n_bogo * b_tn) + (fp_bogo * prob_n_bogo * b_fp)\n",
    "    E_prof_disc = (tp_disc * prob_p_disc * b_tp) + (fn_disc * prob_p_disc * b_fn) + (tn_disc * prob_n_disc * b_tn) + (fp_disc * prob_n_disc * b_fp)\n",
    "\n",
    "                                                    \n",
    "    E_prof = E_prof_bogo + E_prof_disc\n",
    "    #E_prof = E_prof_bogo\n",
    "\n",
    "    \n",
    "    return E_prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57fa87b7-73a2-4ceb-9764-fb9470447f11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train and evaluate classifier \n",
    "from sklearn.metrics import multilabel_confusion_matrix, make_scorer\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "class_score = make_scorer(exp_prof)\n",
    "pipeline_results = cross_validate(pipeline, X, y, cv=2, scoring=class_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2975f64d-c030-40d4-b27f-bbb03cb4ed1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.83194876, 0.80995893]),\n",
       " 'score_time': array([0.12406206, 0.12291932]),\n",
       " 'test_score': array([15007.3388163 , 15733.33517835])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "654ee4b1-053e-40a3-92c0-da0243266514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10195.035004354108\n",
      "7694.297852980068\n",
      "6144.010562956777\n",
      "5085.976078841009\n",
      "4371.596001787399\n",
      "3821.666552321639\n",
      "3418.4648006432253\n"
     ]
    }
   ],
   "source": [
    "for i in range(3,10):\n",
    "    print(cross_validate(pipeline, X, y, cv=i, scoring=class_score)['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098e56b7-be2a-4899-9fe8-768772af0805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REDO THIS FUNCTION, WRITE NOW IT CALCULATES THE TOTAL EXPECTED PROFIT, BUT SHOULD CALCULATE THE EXPECTED PROFIT PER CUSTOMER \n",
    "# ADD CALC FOR PROB OF TP, PROB OF TN, PROB OF FP, PROB OF FN \n",
    "def exp_prof_per_cust(y_test, y_pred):\n",
    "    \n",
    "    # Defining benefits associated with true positive, true negatives\n",
    "    b_tp = 10\n",
    "    b_tn = 0\n",
    "\n",
    "    # Defining costs (or negative benefits) associated with false postives, false negatives\n",
    "    b_fp = -1\n",
    "    b_fn = -10 \n",
    "\n",
    "    # Calculating probabilities needed to compute expected profit \n",
    "\n",
    "    p_bogo = y_test['bogo'].value_counts().sort_index(ascending=True)[1]\n",
    "    n_bogo = y_test['bogo'].value_counts().sort_index(ascending=True)[0]\n",
    "\n",
    "    p_disc = y_test['discount'].value_counts().sort_index(ascending=True)[1]\n",
    "    n_disc = y_test['discount'].value_counts().sort_index(ascending=True)[0]\n",
    "\n",
    "    prob_p_bogo = p_bogo/(p_bogo + n_bogo)\n",
    "    prob_n_bogo = n_bogo/(p_bogo + n_bogo) \n",
    "\n",
    "    prob_p_disc = p_disc/(p_disc + n_disc)\n",
    "    prob_n_disc = n_disc/(p_disc + n_disc)\n",
    "\n",
    "    # Extracting values from confusion matrix \n",
    "\n",
    "    tn_bogo, fp_bogo, fn_bogo, tp_bogo = multilabel_confusion_matrix(y_test, y_pred)[0].ravel()\n",
    "    tn_disc, fp_disc, fn_disc, tp_disc = multilabel_confusion_matrix(y_test, y_pred)[1].ravel()\n",
    "     \n",
    "    p_tp_bogo = tp_bogo/p_bogo\n",
    "    p_\n",
    "\n",
    "    # Expected profit\n",
    "    #E_prof_bogo = (tp_bogo * prob_p_bogo * b_tp) + (fn_bogo * prob_p_bogo * b_fn)+ (tn_bogo * prob_n_bogo * b_tn) + (fp_bogo * prob_n_bogo * b_fp)\n",
    "    #E_prof_disc = (tp_disc * prob_p_disc * b_tp) + (fn_disc * prob_p_disc * b_fn) + (tn_disc * prob_n_disc * b_tn) + (fp_disc * prob_n_disc * b_fp)\n",
    "\n",
    "     # Expected profit\n",
    "    E_prof_bogo = prob_p_bogo *( ) \n",
    "                                                    \n",
    "    E_prof = E_prof_bogo + E_prof_disc\n",
    "    #E_prof = E_prof_bogo\n",
    "\n",
    "    \n",
    "    return E_prof"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
