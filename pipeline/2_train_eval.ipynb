{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starbucks Capstone Challenge \n",
    "## Fit classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.metrics import multilabel_confusion_matrix, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "prep_data = pd.read_pickle('../data/processed/prepared_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data in features (X) and labels (y)\n",
    "X = prep_data.drop(['bogo', 'discount'], axis=1)\n",
    "\n",
    "y = prep_data[['bogo', 'discount']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make preprocessing step to onehotencode features\n",
    "\n",
    "# intantiate OHE\n",
    "categorical_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    \n",
    "# List categorical variables in to be OHE\n",
    "categorical_columns = ['income_group','age_group','gender']\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "        [\n",
    "            ('cat', categorical_encoder, categorical_columns),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intantiate classifier\n",
    "clf = MultiOutputClassifier(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build pipeline\n",
    "model = Pipeline(\n",
    "    [\n",
    "        ('preprocess', preprocessing),\n",
    "        ('classifier', clf),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifier parameters and values for hypertuning \n",
    "parameters = {}\n",
    "parameters['classifier__estimator__n_estimators'] = [10, 20, 50]\n",
    "#parameters['classifier__estimator__criterion'] = ('gini', 'entropy')\n",
    "parameters['classifier__estimator__max_depth'] = [10, 20, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cal_exp_prof(y_test, y_pred):\n",
    "    \n",
    "    '''\n",
    "    This is a custom scorer built for evaluating classifier. \n",
    "    A custom scorer was needed since the pre-builting scorers \n",
    "    (eg accuracy) was not thought to be appropriate for this \n",
    "    classifier. The costs of incorrectly predicting a users \n",
    "    responsivness and the benefits of correctly predicting \n",
    "    a users responsivenss are assummed here to be unequal. \n",
    "    An expected profit per user was calculated following the \n",
    "    methodology outlined in Data Science for Business by \n",
    "    F.Provost and T.Fawcett.\n",
    "    This function returns the expected profit per user based \n",
    "    on the predicted responsivness labels assigned to each user \n",
    "    for BOGO and discount offers compared to the actual offers.\n",
    "    '''\n",
    "    \n",
    "    # Defining benefits associated with true positive, true negatives\n",
    "    b_tp = 10\n",
    "    b_tn = 0\n",
    "\n",
    "    # Defining costs (or negative benefits) associated with false postives, false negatives\n",
    "    b_fp = -1\n",
    "    b_fn = -10 \n",
    "\n",
    "    # Calculating probabilities needed to compute expected profit \n",
    "    p_bogo = y_test['bogo'].value_counts().sort_index(ascending=True)[1]\n",
    "    n_bogo = y_test['bogo'].value_counts().sort_index(ascending=True)[0]\n",
    "\n",
    "    p_disc = y_test['discount'].value_counts().sort_index(ascending=True)[1]\n",
    "    n_disc = y_test['discount'].value_counts().sort_index(ascending=True)[0]\n",
    "\n",
    "    prob_p_bogo = p_bogo/(p_bogo + n_bogo)\n",
    "    prob_n_bogo = n_bogo/(p_bogo + n_bogo) \n",
    "\n",
    "    prob_p_disc = p_disc/(p_disc + n_disc)\n",
    "    prob_n_disc = n_disc/(p_disc + n_disc)\n",
    "\n",
    "    # Extracting values from confusion matrix \n",
    "    tn_bogo, fp_bogo, fn_bogo, tp_bogo = multilabel_confusion_matrix(y_test, y_pred)[0].ravel()\n",
    "    tn_disc, fp_disc, fn_disc, tp_disc = multilabel_confusion_matrix(y_test, y_pred)[1].ravel()\n",
    "     \n",
    "    # Calculating the probability of tn, tp, fn, fp for BOGO and discount offers\n",
    "    p_tp_bogo = tp_bogo/p_bogo\n",
    "    p_tn_bogo = tn_bogo/n_bogo \n",
    "    \n",
    "    p_tp_disc = tp_disc/p_disc\n",
    "    p_tn_disc = tn_disc/n_disc \n",
    "\n",
    "    p_fp_bogo = fp_bogo/n_bogo\n",
    "    p_fn_bogo = fn_bogo/p_bogo\n",
    "\n",
    "    p_fp_disc = fp_disc/n_disc\n",
    "    p_fn_disc = fn_disc/p_disc\n",
    "    \n",
    "\n",
    "     # Expected profit per user for BOGO and discount offers\n",
    "    E_prof_bogo = (prob_p_bogo * (p_tp_bogo * b_tp + p_fn_bogo * b_fn)) + (prob_n_bogo * (p_tn_bogo * b_tn + p_fp_bogo * b_fp))\n",
    "                                                    \n",
    "    E_prof_disc = (prob_p_disc * (p_tp_disc * b_tp + p_fn_disc * b_fn)) + (prob_n_disc * (p_tn_disc * b_tn + p_fp_disc * b_fp))\n",
    "\n",
    "   # Total expected profit per user\n",
    "    E_prof = E_prof_bogo + E_prof_disc\n",
    "    \n",
    "    return E_prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare custom scorer for use in GridSearchCV and cross validation\n",
    "class_score = make_scorer(cal_exp_prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocess',\n",
       "                                        ColumnTransformer(transformers=[('cat',\n",
       "                                                                         OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                                         ['income_group',\n",
       "                                                                          'age_group',\n",
       "                                                                          'gender'])])),\n",
       "                                       ('classifier',\n",
       "                                        MultiOutputClassifier(estimator=RandomForestClassifier()))]),\n",
       "             param_grid={'classifier__estimator__max_depth': [10, 20, 30],\n",
       "                         'classifier__estimator__n_estimators': [10, 20, 50]},\n",
       "             scoring=make_scorer(cal_exp_prof))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply GridSearchCV to pipeline using crossvalidation \n",
    "mod_tun = GridSearchCV(model, param_grid=parameters, cv=5, scoring=class_score)\n",
    "\n",
    "# Fit pipeline on data to determine best parameters using crossvalidation \n",
    "# for train and test splits and custom scoring metric. \n",
    "mod_tun.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__estimator__max_depth': 20,\n",
       " 'classifier__estimator__n_estimators': 10}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get best parameters \n",
    "mod_tun.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.60559250994636"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_tun.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
