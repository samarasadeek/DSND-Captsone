{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starbucks Capstone Challenge: Train and evaluate classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "1. Load prepared data. \n",
    "2. Build pipeline.\n",
    "3. Define metric function for crossvalidation (expected profit per user).\n",
    "4. Tune classifier and record classifier performance.\n",
    "5. References."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle \n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV, cross_validate\n",
    "from sklearn.metrics import multilabel_confusion_matrix, make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load prepared data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data \n",
    "prep_data = pd.read_pickle('../data/processed/prepared_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data in features (X) and labels (y)\n",
    "X = prep_data.drop(['bogo', 'discount'], axis=1)\n",
    "\n",
    "y = prep_data[['bogo', 'discount']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Building pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make preprocessing step to onehotencode features\n",
    "\n",
    "# intantiate OHE\n",
    "categorical_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    \n",
    "# List categorical variables in to be OHE\n",
    "categorical_columns = ['income_group','age_group','gender']\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "        [\n",
    "            ('cat', categorical_encoder, categorical_columns),\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intantiate classifier\n",
    "clf = MultiOutputClassifier(BernoulliNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build pipeline\n",
    "model = Pipeline(\n",
    "    [\n",
    "        ('preprocess', preprocessing),\n",
    "        ('classifier', clf),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Define metric function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cal_exp_prof(y_test, y_pred):\n",
    "    \n",
    "    '''\n",
    "    This is a custom scorer built for evaluating classifier. \n",
    "    A custom scorer was needed since the pre-builting scorers \n",
    "    (eg accuracy) was not thought to be appropriate for this \n",
    "    classifier. The costs of incorrectly predicting a users \n",
    "    responsivness and the benefits of correctly predicting \n",
    "    a users responsivenss are assummed here to be unequal. \n",
    "    An expected profit per user was calculated following the \n",
    "    methodology outlined in Data Science for Business by \n",
    "    F.Provost and T.Fawcett.\n",
    "    This function returns the expected profit per user based \n",
    "    on the predicted responsivness labels assigned to each user \n",
    "    for BOGO and discount offers compared to the actual offers.\n",
    "    '''\n",
    "    \n",
    "    # Defining benefits associated with true positive, true negatives\n",
    "    b_tp = 10\n",
    "    b_tn = 0\n",
    "\n",
    "    # Defining costs (or negative benefits) associated with false postives, false negatives\n",
    "    b_fp = -1\n",
    "    b_fn = -10 \n",
    "\n",
    "    # Calculating probabilities needed to compute expected profit \n",
    "    p_bogo = y_test['bogo'].value_counts().sort_index(ascending=True)[1]\n",
    "    n_bogo = y_test['bogo'].value_counts().sort_index(ascending=True)[0]\n",
    "\n",
    "    p_disc = y_test['discount'].value_counts().sort_index(ascending=True)[1]\n",
    "    n_disc = y_test['discount'].value_counts().sort_index(ascending=True)[0]\n",
    "\n",
    "    prob_p_bogo = p_bogo/(p_bogo + n_bogo)\n",
    "    prob_n_bogo = n_bogo/(p_bogo + n_bogo) \n",
    "\n",
    "    prob_p_disc = p_disc/(p_disc + n_disc)\n",
    "    prob_n_disc = n_disc/(p_disc + n_disc)\n",
    "\n",
    "    # Extracting values from confusion matrix \n",
    "    tn_bogo, fp_bogo, fn_bogo, tp_bogo = multilabel_confusion_matrix(y_test, y_pred)[0].ravel()\n",
    "    tn_disc, fp_disc, fn_disc, tp_disc = multilabel_confusion_matrix(y_test, y_pred)[1].ravel()\n",
    "     \n",
    "    # Calculating the probability of tn, tp, fn, fp for BOGO and discount offers\n",
    "    p_tp_bogo = tp_bogo/p_bogo\n",
    "    p_tn_bogo = tn_bogo/n_bogo \n",
    "    \n",
    "    p_tp_disc = tp_disc/p_disc\n",
    "    p_tn_disc = tn_disc/n_disc \n",
    "\n",
    "    p_fp_bogo = fp_bogo/n_bogo\n",
    "    p_fn_bogo = fn_bogo/p_bogo\n",
    "\n",
    "    p_fp_disc = fp_disc/n_disc\n",
    "    p_fn_disc = fn_disc/p_disc\n",
    "    \n",
    "\n",
    "     # Expected profit per user for BOGO and discount offers\n",
    "    E_prof_bogo = (prob_p_bogo * (p_tp_bogo * b_tp + p_fn_bogo * b_fn)) + (prob_n_bogo * (p_tn_bogo * b_tn + p_fp_bogo * b_fp))\n",
    "                                                    \n",
    "    E_prof_disc = (prob_p_disc * (p_tp_disc * b_tp + p_fn_disc * b_fn)) + (prob_n_disc * (p_tn_disc * b_tn + p_fp_disc * b_fp))\n",
    "\n",
    "   # Total expected profit per user\n",
    "    E_prof = E_prof_bogo + E_prof_disc\n",
    "    \n",
    "    return E_prof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Tune classifier and record classifier performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define classifier parameters and values for hypertuning \n",
    "parameters = {}\n",
    "parameters['classifier__estimator__alpha'] = [1,2,3]\n",
    "parameters['classifier__estimator__fit_prior'] = (True, False)\n",
    "parameters['classifier__estimator__binarize'] = [0,1,2,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare custom scorer for use in GridSearchCV and cross validation\n",
    "class_score = make_scorer(cal_exp_prof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters are: {'classifier__estimator__alpha': 1, 'classifier__estimator__binarize': 0, 'classifier__estimator__fit_prior': True}\n",
      "Highest expected profit per user: 6.749981633623442\n"
     ]
    }
   ],
   "source": [
    "# Apply GridSearchCV to pipeline using crossvalidation \n",
    "mod_tun = GridSearchCV(model, param_grid=parameters, cv=5, scoring=class_score)\n",
    "\n",
    "# Fit pipeline on data to determine best parameters using crossvalidation \n",
    "# for train and test splits and custom scoring metric. \n",
    "mod_tun.fit(X,y);\n",
    "\n",
    "print('Best parameters are: {}'.format(mod_tun.best_params_))\n",
    "print('Highest expected profit per user: {}'.format(mod_tun.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record performance of classifier \n",
    "with open('../experimentlog.txt', 'a') as f:\n",
    "    f.write('\\n \\n {}: \\n {} \\n {} Expected profit per user: {}'. format(datetime.now(), mod_tun, mod_tun.best_params_, mod_tun.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References \n",
    "1. Provost, F. & Fawcett, T. (2013) Data Science for Business. 1st edition. United States of America, Oâ€™Reilly Media, Inc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
